{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMztDbrYFAZnda+9SiZkiKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuyeongKime2/Credit-card-fraud-detecting-system/blob/main/Final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[B주제 : credit card fraud detecting system (신용카드 이상거래 감지 프로그램)]**\n",
        "\n",
        "* 약 28만건의 신용카드 거래 데이터 중에서 이상거래(Fraud)를 감지해내는 프로그램\n",
        "\n",
        "- 사용 데이터 : credit card fraud transaction dataset (Kaggle)\n",
        "- 실습 환경: Google Colab notebooks\n",
        "- 학습 언어: Python3"
      ],
      "metadata": {
        "id": "m5AiIUcoRuPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module Import**"
      ],
      "metadata": {
        "id": "egHLoSaJSsuO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF-uew60RfZq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Access Google Drive files**"
      ],
      "metadata": {
        "id": "INqefPzaSAYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VpW_IvRhSQN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Data Load**"
      ],
      "metadata": {
        "id": "w64YgLbaTDUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load a CSV file from Google Drive using pandas\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset/creditcard (1).csv\", delimiter=',', dtype=np.float32)\n",
        "\n",
        "#DataFrame의 행과 열의 개수를 튜플 형태로 반환 후 출력\n",
        "print(df.shape)\n",
        "\n",
        "#DataFrame의 상위 5개 행을 출력\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CntYWwzBTJVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Missing Value Check**"
      ],
      "metadata": {
        "id": "IzvtNQUWeb3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Index Range: DataFrame의 인덱스 범위.\n",
        "* Column Names: 각 열의 이름.\n",
        "* Non-Null Count: 각 열에서 결측값이 아닌 non-null 값의 개수.\n",
        "* Dtype: 각 열의 데이터 유형(data type).\n",
        "* Memory Usage: DataFrame이 사용하는 메모리 양.\n",
        "\n"
      ],
      "metadata": {
        "id": "dHWB-eK6q4yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1차 검수 : df의 요약 정보를 출력\n",
        "df.info()\n",
        "\n",
        "# 결측값 존재 여부확인\n",
        "\n",
        "\"\"\"\n",
        "df.isnull().sum().sum() : DataFrame 전체에서 결측값의 총 개수를 계산\n",
        "결측값이 하나도 없으면 \"결측값이 존재하지 않음\"을 출력하고,\n",
        "결측값이 하나라도 있으면 \"결측값이 존재함\"을 출력\n",
        "\n",
        "\"\"\"\n",
        "if df.isnull().sum().sum() == 0:\n",
        "    print(\"결측값이 존재하지 않음\")\n",
        "else:\n",
        "    print(\"결측값이 존재함\")"
      ],
      "metadata": {
        "id": "Yz928anTWHV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2차 검수 : 각 변수에 대해 결측값 존재여부 확인\n",
        "df.isnull().sum() / df.shape[0]"
      ],
      "metadata": {
        "id": "eAOQTF0BGy9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Visualize(상관관계 시각화)**\n"
      ],
      "metadata": {
        "id": "5NI6G11Ju2z3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**상관계수 (Correlation Coefficient):**\\\n",
        " -1에서 1 사이의 값을 가지며, 두 변수 간의 선형 관계를 나타낸다.\n",
        "\n",
        "* 1: 완벽한 양의 상관관계 (두 변수가 함께 증가)\n",
        "* -1: 완벽한 음의 상관관계 (한 변수가 증가할 때 다른 변수는 감소)\n",
        "* 0: 상관관계 없음 (두 변수 간에 선형 관계가 없음)"
      ],
      "metadata": {
        "id": "I9eazsaNQd34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Seaborn 스타일 설정\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# 그래프 크기 설정\n",
        "f, ax = plt.subplots(figsize=(25, 15))\n",
        "\n",
        "# 상관 행렬 계산\n",
        "corr = df.corr()\n",
        "\n",
        "# 상관 행렬에서 결측값을 0으로 대체 (필요 시)\n",
        "corr = corr.fillna(0)\n",
        "\n",
        "# 히트맵 그리기\n",
        "heatmap = sns.heatmap(corr, annot=True, linewidths=0.3, fmt=\".2f\", ax=ax, cmap=\"viridis\", cbar_kws={\"shrink\": 0.5})\n",
        "\n",
        "# 그래프 제목 추가\n",
        "plt.title('Correlation Heatmap', fontsize=20)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "가독성을 개선하기 위한 옵션 추가\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# x축과 y축 레이블 회전\n",
        "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)\n",
        "\n",
        "# 색상 바 추가\n",
        "cbar = heatmap.collections[0].colorbar\n",
        "cbar.set_label('Correlation Coefficient', fontsize=15)\n",
        "\n",
        "# 상관계수 조건부 강조 (절대값이 0.8 이상인 경우 붉은색으로 강조)\n",
        "for i in range(len(corr.columns)):\n",
        "    for j in range(len(corr.columns)):\n",
        "        if abs(corr.iloc[i, j]) >= 0.8:\n",
        "            heatmap.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='r', lw=3))\n",
        "\n",
        "# 그래프 표시\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A5hsqW2ru6Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   결과적으로, Feature들 사이의 상관관계가 매우 낮게 나옴\n",
        "\n",
        "* 즉, 상관계수가 0.8 이상이 아니므로 다중공선성의 가능성이 낮기 때문에 다중공선성을 줄일 필요는 없다.\n",
        "\n"
      ],
      "metadata": {
        "id": "z6mttkff5mra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA (Exploaratory Data Analysis, 탐색적 데이터 분석)\n",
        "\n",
        "데이터의 전체적인 구조 파악"
      ],
      "metadata": {
        "id": "C1bpEpLediHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"Class\" 열의 값 빈도 계산\n",
        "class_counts = df[\"Class\"].value_counts()\n",
        "class_ratios = df[\"Class\"].value_counts(normalize=True)\n",
        "\n",
        "# 클래스 수\n",
        "print(\"Class Counts:\\n\", class_counts)\n",
        "\n",
        "#클래스 비율\n",
        "print(\"\\nClass Ratios:\\n\", class_ratios)"
      ],
      "metadata": {
        "id": "4ucjDuiEdhAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 0.0 : 정상거래 / 1.0 : 이상거래\n",
        "* 정상거래는 28만 4315건, 이상거래는 492건이 존재\n",
        "* 전체 데이터셋에서 오직 0.0017%가 이상거래이므로 심각한 imbalance(불균형)가 존재하는 dataset임을 파악할 수 있음.\n",
        "\n",
        "\n",
        "* 일반적인 상황에서 주로 사용되는 Accuracy(정확도)를 사용해서 모델의 Performance(성능)를 측정하기 어렵다는 결론이 도출"
      ],
      "metadata": {
        "id": "LqXQqgecvCyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Precision, Recall, F1 Score를 사용한 모델설계**\n",
        "\n",
        "* Precision(정밀도): 모델이 True라고 분류한 것 중에서 실제 True가 차지하는 비중\n",
        "\n",
        "* Recall(재현률): 실제 True 중에서 모델이 True라고 분류한 데이터의 비중\n",
        "\n",
        "* F1 score: Precision과 Recall의 조화평균\n"
      ],
      "metadata": {
        "id": "LHKv6PktwhVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Data imabalance가 얼마나 심한지 시각화를 통해서 확인\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# 특징 (X)과 레이블 (y) 분리\n",
        "X = df.drop('Class', axis=1)  # 'class' 열을 제외한 모든 열을 특징으로 사용\n",
        "y = df['Class']\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 학습 (예시: 로지스틱 회귀)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Precision, Recall, F1 Score 계산\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "#Visualize\n",
        "labels = [\"Normal\", \"Fraud\"]\n",
        "\n",
        "# count_classes가 각 클래스의 개수를 담고 있는 Series라고 가정\n",
        "class_counts.plot(kind=\"bar\")\n",
        "plt.xticks(range(2), labels, rotation=0)  # x축 레이블을 0도(수평)로 회전\n",
        "plt.title(\"Transaction Class Distribution\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ki-5S29yvW02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "[현재 모델의 성능 지표]\\\n",
        "\\\n",
        "정밀도: 61.11%\\\n",
        "재현율: 56.12%\\\n",
        "F1 스코어: 58.51%\n",
        "\n",
        "\n",
        "\\\n",
        "결과: 모델이 사기 거래를 예측하는 데 있어서 어느 정도의 성능을 보여주고 있지만, 여전히 개선의 여지가 있음을 나타냄. 특히 재현율이 낮기 때문에 실제 사기 거래를 많이 놓치고 있을 가능성이 있음."
      ],
      "metadata": {
        "id": "aej-6LwYz9Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data imabalance(데이터 불균형) 가 얼마나 심한지 시각화를 통해서 확인"
      ],
      "metadata": {
        "id": "3rHqG-PDbPcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = \"Time\", inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jgcz6e8RbR_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time이라는 Feature는 단순히 신용카드 거래가 이루어진 순서를\n",
        "기록한 것이기 때문에 분석에 크게 도움이 되지 않으므로 데이터 테이블에서 배제"
      ],
      "metadata": {
        "id": "0189p0ZJbYzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_data와 y_data를 numpy 배열로 변환하고 데이터 타입을 float32로 설정\n",
        "x_data = df.iloc[:, :-1].to_numpy(dtype=np.float32)\n",
        "y_data = df.iloc[:, -1].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
        "\"\"\"\n",
        "가독성을 높이기 위한 코드:\n",
        "\n",
        "to_numpy() 메서드를 사용하여 DataFrame을 numpy 배열로 변환하고,\n",
        "dtype 인자를 사용하여 데이터 타입을 지정.\n",
        "reshape(-1, 1)을 사용하여 y_data를 2차원 배열로 변환\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 배열의 형태 출력\n",
        "print(x_data.shape, y_data.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tnTCNR0abdJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature들로 이루어진 x_data와, label을 나타내는 y_data로 원본 데이터를 분리. 분리된 데이터는 앞으로 계산을 해주어야 하기 때문에 동일한 타입의 실수형 데이터로 저장\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v2p-OCA9cfK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing - Normalize (데이터전처리-정규화)**"
      ],
      "metadata": {
        "id": "lWbz_yxmc9eX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터의 Scale에 따라서 결과가 왜곡되는 것을 방지하기 위해서 MinMaxScaler를 통해서 데이터가 0~1 사이의 값을 지니도록 조정해줌"
      ],
      "metadata": {
        "id": "j73PD8apdcaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# 데이터 스케일링\n",
        "x_data = pd.DataFrame(scaler.fit_transform(x_data))\n",
        "\"\"\"\n",
        "MinMaxScaler는 fit_transform 메서드를 사용하여 데이터를 0과 1 사이로 변환\n",
        "결과적으로 각 특성의 최소값은 0, 최대값은 1\n",
        "\n",
        "\"\"\"\n",
        "# 스케일된 데이터 출력\n",
        "print(f\"스케일된 데이터:\\n\\n\", x_data.head)"
      ],
      "metadata": {
        "id": "4M_6aC-vcpLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 랜덤 포레스트 모델은 트리 기반 모델로, 각 특성의 스케일에 크게 영향을 받지 않아 정규화가 필수적이지 않지만, 데이터 전처리 과정에서 이상치(outlier)를 줄이고 모델의 안정성을 높이기 위해 정규화를 수행할 수 있음"
      ],
      "metadata": {
        "id": "jlneZmxlJ4_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RandomForest(랜덤 포레스트)**"
      ],
      "metadata": {
        "id": "zStykS8gnYnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 포레스트는 결정 트리 기반의 앙상블 모델로, 경사 하강법을 사용하지 않기 때문에 learning rate와 optimizer를 설정할 필요가 없음.\\\n",
        "대신, 랜덤 포레스트 모델을 구현할 때는 다음과 같은 하이퍼파라미터들을 조정할 수 있다."
      ],
      "metadata": {
        "id": "OUm1UuaYnecr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 랜덤 포레스트 모델 생성\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)  # n_estimators는 트리 개수\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터 예측\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 성능 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "Cll22mosndL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "IyObl8rRuMym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[성능 지표 해석]\n",
        "\n",
        "* Accuracy: 0.9996\n",
        "해석: 모델이 전체 데이터 중 약 99.96%를 올바르게 예측\n",
        "\n",
        "* Precision: 0.9740\n",
        "해석: 모델이 사기 거래라고 예측한 것 중 약 97.40%가 실제로 사기 거래\\\n",
        "높은 정밀도: False Positive가 적다는 것을 의미. 즉, 잘못된 양성 예측이 비교적 적음\n",
        "\n",
        "* Recall: 0.7653\n",
        "해석: 실제 사기 거래 중 약 76.53%를 모델이 정확히 예측.\\\n",
        "낮은 재현율: False Negative가 많다는 것을 의미. 즉, 실제로 사기 거래인 경우를 모델이 놓치는 경우가 많음.\n",
        "\n",
        "* F1 Score: 0.8571\n",
        "해석: 모델이 사기 거래를 예측하는 데 있어서 정밀도와 재현율의 균형이 약 85.71%\\\n",
        "균형 지표: 정밀도와 재현율이 모두 중요할 때 유용한 지표"
      ],
      "metadata": {
        "id": "HntQaoH96nSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과적으로 랜덤포레스트 모델로 F1 score가 높게 나온 것을 알 수 있음.\n",
        "\n",
        "그러나,\n",
        "높은 정밀도를 가지고 있지만,재현율이 낮아 실제 사기 거래를 많이 놓치고 있다. 성능향상이 필요할 듯함"
      ],
      "metadata": {
        "id": "S4tEpANu_xQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Threshold Adjustment(임계값 조정)**\n",
        "\n",
        "모델의 예측 확률에 대해 임계값(Threshold)을 조정하여 재현율을 높일 수 있음. 예를들어, 기본적으로 0.5로 설정된 임계값을 낮추면 더 많은 거래를 사기 거래로 분류하게 되어 재현율이 높아질 수 있음"
      ],
      "metadata": {
        "id": "J5CvmU-pS03c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# 랜덤 포레스트 모델 생성 (n_estimators는 트리 개수)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터에 대한 예측 확률 계산\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 정밀도-재현율 곡선 계산\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# F1 스코어 계산 및 최적 임계값 찾기\n",
        "f1_scores = 2 * precision * recall / (precision + recall)\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "# 최적 임계값을 사용하여 예측값 생성\n",
        "y_pred = (y_scores >= optimal_threshold).astype(int)\n",
        "\n",
        "# 새로운 정밀도, 재현율, 정확도, F1 점수 계산\n",
        "new_precision = precision_score(y_test, y_pred)\n",
        "new_recall = recall_score(y_test, y_pred)\n",
        "new_accuracy = accuracy_score(y_test, y_pred)\n",
        "new_f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "print(f\"New Precision: {new_precision}\")\n",
        "print(f\"New Recall: {new_recall}\")\n",
        "print(f\"New Accuracy: {new_accuracy}\")\n",
        "print(f\"New F1 Score: {new_f1}\")"
      ],
      "metadata": {
        "id": "SxSZj1X5gx3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[성능 지표 분석]\n",
        "\n",
        "Precision (정밀도):\n",
        " 정밀도가 0.9518로 매우 높음. 이는 모델이 긍정 예측을 할 때 대부분 정확\n",
        "\n",
        "Recall (재현율):\n",
        "재현율이 0.8061로 상당히 높음. 모델이 실제 긍정 클래스의 대부분을 올바르게 예측\n",
        "\n",
        "Accuracy (정확도):\n",
        "정확도가 0.9996로 매우 높음. 모델이 대부분의 예측을 정확하게 하고있음\n",
        "\n",
        "F1 Score:\n",
        "F1 점수가 0.8729로 매우 높음. 이는 모델의 전반적인 성능이 매우 좋다는 것을 의미\n",
        "\n",
        "결론:\n",
        "\n",
        "이 모델은 정밀도, 재현율, 정확도, F1 점수 모두 매우 높은 수준.\n",
        " 이는 모델이 긍정 클래스를 잘 예측할 뿐만 아니라, 전체적으로도 매우 정확하게 예측하고 있다는 것을 의미한다.\n",
        "\n",
        "다만, 재현율을 조금 더 높일 수 있다면 더 완벽한 모델이 될 수 있을 것이므로 모델의 하이퍼파라미터 튜닝을 고려해봐도 좋음."
      ],
      "metadata": {
        "id": "-QeANP3_mYQh"
      }
    }
  ]
}